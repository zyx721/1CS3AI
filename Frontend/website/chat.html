<!-- index.html - The Frontend -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Visualizer - Bioluminescent</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg-dark: #131414;
            --text-light: #F5F4F0;
            --green-accent: #79B266;
            --green-dark: #2E402B;
            --color-top-right: #3F5230;
            --color-bottom-right: #AEB881;
            --color-left: #1D221C;
            --color-middle: #3B5428;
            /* Re-aliasing for clarity in button styles */
            --primary-text: var(--text-light);
            --secondary-text: #b0b0b0;
            --accent-color-1: var(--green-accent);
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: 'Poppins', sans-serif;
            background: radial-gradient(circle at 25% 35%, #789d6e 0%, rgba(46, 64, 43, 0) 30%),
                        radial-gradient(circle at 75% 65%, #6a905e 0%, rgba(46, 64, 43, 0) 28%),
                        var(--bg-dark);
            background-color: var(--bg-dark);
            color: var(--text-light);
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }

        #ai-voice-canvas {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 1; cursor: pointer;
            filter: blur(2.5px) brightness(1.15) saturate(1.2);
        }

        .ui-container {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 2; text-align: center; padding: 2rem;
            background: rgba(0, 0, 0, 0.1); backdrop-filter: blur(5px);
            display: flex; justify-content: center; align-items: center;
            transition: opacity 0.7s cubic-bezier(.4,0,.2,1);
        }
        .ui-container.hidden { opacity: 0; pointer-events: none; }

        .title {
            font-size: 3rem; font-weight: 600; letter-spacing: 1px;
            background: linear-gradient(90deg, var(--green-accent), var(--color-bottom-right));
            background-clip: text; -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 0.5rem; text-shadow: 0 0 20px #79B26644;
        }

        .subtitle { font-size: 1.2rem; font-weight: 300; color: var(--secondary-text); margin-bottom: 2rem; }

        #startButton {
            font-family: 'Poppins', sans-serif; font-size: 1rem; font-weight: 600;
            color: var(--primary-text); background: transparent;
            border: 2px solid var(--accent-color-1); padding: 0.8rem 2.5rem;
            border-radius: 50px; cursor: pointer;
            transition: all 0.3s ease; letter-spacing: 1px; margin-bottom: 1.5rem;
        }
        #startButton:hover { background: var(--accent-color-1); color: var(--bg-dark); box-shadow: 0 0 25px var(--accent-color-1); }
        #startButton:disabled { opacity: 0.5; cursor: not-allowed; box-shadow: none; background: transparent; color: var(--primary-text); }

        .status-text { font-weight: 300; color: var(--secondary-text); min-height: 1.2em; transition: opacity 0.3s ease; }

        @media (max-width: 600px) {
            .title { font-size: 2rem; }
            .subtitle { font-size: 1rem; }
        }
    </style>
</head>
<body>
    <canvas id="ai-voice-canvas"></canvas>

    <main class="ui-container" id="ui-container">
        <div>
            <h1 class="title">AI Voice Visualizer</h1>
            <p class="subtitle">Bioluminescent, voice-reactive 3D sphere</p>
            <button id="startButton">START</button>
            <p id="status" class="status-text"></p>
        </div>
    </main>

    <script type="importmap">
        { "imports": { "three": "https://unpkg.com/three@0.157.0/build/three.module.js" } }
    </script>

    <script type="module">
        import * as THREE from 'three';

        // --- DOM ELEMENTS ---
        const canvas = document.getElementById('ai-voice-canvas');
        const startButton = document.getElementById('startButton');
        const statusText = document.getElementById('status');
        const uiContainer = document.getElementById('ui-container');

        // --- BASIC THREE.JS SETUP ---
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 5.5;
        const renderer = new THREE.WebGLRenderer({ canvas: canvas, antialias: true, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));

        // --- AUDIO PROCESSING ---
        let audioContext, analyser, dataArray, microphone;
        let smoothedLoudness = 0;
        let loudness = 0;
        let audioActive = false;

        async function initAudio() {
            if (audioActive) return;
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                dataArray = new Uint8Array(analyser.frequencyBinCount);

                audioActive = true; // Set active flag on success
                startButton.disabled = true;
                statusText.textContent = "Listening...";
                setTimeout(() => uiContainer.classList.add('hidden'), 700);
            } catch (err) {
                audioActive = false;
                console.error("Error accessing microphone:", err);
                statusText.textContent = "Microphone access denied. Please allow access and refresh.";
            }
        }

        // --- BACKEND CONNECTION ---
        // Note: Ensure this IP address matches your Python server's address.
        // The Python server must be started with host='0.0.0.0' to accept network connections.
        async function startVoiceAgentBackend() {
            try {
                // Use localhost for local development
                const response = await fetch("http://localhost:8080/start-voice-agent");
                if (!response.ok) {
                    throw new Error(`Server responded with status: ${response.status}`);
                }
                const data = await response.json();
                console.log("Voice Agent Started:", data);
            } catch (error) {
                console.error("Failed to start voice agent:", error);
                statusText.textContent = "âŒ Agent connection failed. Is the server running?";
                // Revert UI changes if the backend call fails
                startButton.disabled = false;
                audioActive = false;
                uiContainer.classList.remove('hidden');
            }
        }

        let ws; // WebSocket for audio streaming

        async function streamMicToBackend() {
            // Connect to backend WebSocket
            ws = new WebSocket("ws://localhost:8080/ws-audio");
            ws.binaryType = "arraybuffer";

            ws.onopen = async () => {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioCtx.createMediaStreamSource(stream);
                    const processor = audioCtx.createScriptProcessor(1024, 1, 1);

                    source.connect(processor);
                    processor.connect(audioCtx.destination);

                    processor.onaudioprocess = (e) => {
                        // Get PCM data from input buffer
                        const input = e.inputBuffer.getChannelData(0);
                        // Convert Float32 [-1,1] to Int16 PCM
                        const pcm = new Int16Array(input.length);
                        for (let i = 0; i < input.length; i++) {
                            pcm[i] = Math.max(-32768, Math.min(32767, input[i] * 32767));
                        }
                        if (ws.readyState === 1) {
                            ws.send(pcm.buffer);
                        }
                    };

                    ws.onclose = () => {
                        processor.disconnect();
                        source.disconnect();
                        audioCtx.close();
                    };
                } catch (err) {
                    statusText.textContent = "Microphone access denied. Please allow access and refresh.";
                }
            };

            ws.onerror = (e) => {
                statusText.textContent = "WebSocket error: " + e.message;
            };
        }

        // This function orchestrates the entire start-up process.
        async function startSequence() {
            if (startButton.disabled) return;
            // 1. Request microphone access and initialize audio visualizer.
            await initAudio();
            // 2. If microphone is ready, contact the backend to start the agent.
            if (audioActive) {
                await startVoiceAgentBackend();
                await streamMicToBackend();
            }
        }

        // --- SHADER DEFINITIONS (Unchanged) ---
        const vertexShader = `
            uniform float u_time; uniform float u_loudness;
            varying vec3 v_normal; varying vec2 v_uv;
            vec3 mod289(vec3 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
            vec4 mod289(vec4 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
            vec4 permute(vec4 x) { return mod289(((x*34.0)+1.0)*x); }
            vec4 taylorInvSqrt(vec4 r) { return 1.79284291400159 - 0.85373472095314 * r; }
            float snoise(vec3 v) {
                const vec2 C = vec2(1.0/6.0, 1.0/3.0); const vec4 D = vec4(0.0, 0.5, 1.0, 2.0);
                vec3 i  = floor(v + dot(v, C.yyy)); vec3 x0 = v - i + dot(i, C.xxx);
                vec3 g = step(x0.yzx, x0.xyz); vec3 l = 1.0 - g;
                vec3 i1 = min(g.xyz, l.zxy); vec3 i2 = max(g.xyz, l.zxy);
                vec3 x1 = x0 - i1 + C.xxx; vec3 x2 = x0 - i2 + C.yyy; vec3 x3 = x0 - D.yyy;
                i = mod289(i);
                vec4 p = permute(permute(permute( i.z + vec4(0.0, i1.z, i2.z, 1.0)) + i.y + vec4(0.0, i1.y, i2.y, 1.0)) + i.x + vec4(0.0, i1.x, i2.x, 1.0));
                float n_ = 0.142857142857; vec3 ns = n_ * D.wyz - D.xzx;
                vec4 j = p - 49.0 * floor(p * ns.z * ns.z);
                vec4 x_ = floor(j * ns.z); vec4 y_ = floor(j - 7.0 * x_);
                vec4 x = x_ * ns.x + ns.yyyy; vec4 y = y_ * ns.x + ns.yyyy;
                vec4 h = 1.0 - abs(x) - abs(y); vec4 b0 = vec4(x.xy, y.xy); vec4 b1 = vec4(x.zw, y.zw);
                vec4 s0 = floor(b0)*2.0 + 1.0; vec4 s1 = floor(b1)*2.0 + 1.0; vec4 sh = -step(h, vec4(0.0));
                vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy; vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww;
                vec3 p0 = vec3(a0.xy,h.x); vec3 p1 = vec3(a0.zw,h.y); vec3 p2 = vec3(a1.xy,h.z); vec3 p3 = vec3(a1.zw,h.w);
                vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2,p2), dot(p3,p3)));
                p0 *= norm.x; p1 *= norm.y; p2 *= norm.z; p3 *= norm.w;
                vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);
                m = m * m; return 42.0 * dot(m*m, vec4(dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3)));
            }
            void main() {
                v_normal = normal; v_uv = uv;
                float noise = 0.1 * snoise(normal + u_time * 0.1);
                float displacement = u_loudness * 1.5;
                vec3 newPosition = position + normal * (noise + displacement);
                gl_Position = projectionMatrix * modelViewMatrix * vec4(newPosition, 1.0);
            }
        `;
        const fragmentShader = `
            uniform float u_time; uniform float u_loudness;
            uniform vec3 u_color1; uniform vec3 u_color2; uniform vec3 u_color3;
            varying vec3 v_normal; varying vec2 v_uv;
            void main() {
                float time_factor = sin(u_time * 0.5 + v_normal.y * 5.0);
                vec3 color = mix(u_color1, u_color2, v_normal.y * 0.5 + 0.5);
                color = mix(color, u_color3, v_normal.x * 0.5 + 0.5);
                color = mix(color, u_color1, time_factor);
                float fresnel = 1.0 - dot(v_normal, vec3(0.0, 0.0, 1.0));
                fresnel = pow(fresnel, 2.0);
                vec3 final_color = color + fresnel * u_loudness * 1.5;
                gl_FragColor = vec4(final_color, 1.0);
            }
        `;

        // --- 3D SPHERE (Unchanged) ---
        const sphereGeometry = new THREE.SphereGeometry(1.8, 128, 128);
        const sphereMaterial = new THREE.ShaderMaterial({
            vertexShader, fragmentShader,
            uniforms: {
                u_time: { value: 0.0 }, u_loudness: { value: 0.0 },
                u_color1: { value: new THREE.Color('#1D221C') },
                u_color2: { value: new THREE.Color('#79B266') },
                u_color3: { value: new THREE.Color('#AEB881') },
            },
        });
        const sphere = new THREE.Mesh(sphereGeometry, sphereMaterial);
        scene.add(sphere);

        // --- ANIMATION LOOP ---
        const clock = new THREE.Clock();
        function animate() {
            requestAnimationFrame(animate);
            const elapsedTime = clock.getElapsedTime();
            if (analyser) {
                analyser.getByteFrequencyData(dataArray);
                let sum = dataArray.reduce((a, b) => a + b, 0);
                loudness = (sum / dataArray.length) / 128.0;
            }
            smoothedLoudness += (loudness - smoothedLoudness) * 0.1;
            sphere.material.uniforms.u_time.value = elapsedTime;
            sphere.material.uniforms.u_loudness.value = smoothedLoudness;
            sphere.rotation.y = elapsedTime * 0.12;
            sphere.rotation.x = elapsedTime * 0.06;
            renderer.render(scene, camera);
        }

        // --- EVENT LISTENERS ---
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
        });

        startButton.addEventListener('click', startSequence);
        startButton.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' || e.key === ' ') {
                e.preventDefault();
                startSequence();
            }
        });

        // --- STATE HANDLING (Unchanged) ---
        const palettes = {
            user: { u_color1: "#1D221C", u_color2: "#79B266", u_color3: "#AEB881" },
            agent: { u_color1: "#2E402B", u_color2: "#FFD700", u_color3: "#7EC8E3" }
        };
        function setVisualizerState(state) {
            const pal = palettes[state] || palettes.user;
            sphere.material.uniforms.u_color1.value.set(pal.u_color1);
            sphere.material.uniforms.u_color2.value.set(pal.u_color2);
            sphere.material.uniforms.u_color3.value.set(pal.u_color3);
        }

        window.addEventListener('keydown', (e) => {
            if (e.key.toLowerCase() === 'u') setVisualizerState('user');
            if (e.key.toLowerCase() === 'a') setVisualizerState('agent');
        });

        // Start the animation loop
        animate();
    </script>
</body>
</html>